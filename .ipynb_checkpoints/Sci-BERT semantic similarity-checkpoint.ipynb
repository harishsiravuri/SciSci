{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>Traditional recurrent neural network (RNN) or ...</td>\n",
       "      <td>This paper proposes a tree-to-tree model aimin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>Traditional recurrent neural network (RNN) or ...</td>\n",
       "      <td>This paper presents a model to encode and deco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>We study the problem of knowledge base (KB) em...</td>\n",
       "      <td>The paper proposes a unified view of multiple ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>We study the problem of knowledge base (KB) em...</td>\n",
       "      <td>This paper deals with the problem of represent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>We study the problem of knowledge base (KB) em...</td>\n",
       "      <td>The paper proposes a new method to train knowl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               abstract  \\\n",
       "2743  Traditional recurrent neural network (RNN) or ...   \n",
       "2744  Traditional recurrent neural network (RNN) or ...   \n",
       "2745  We study the problem of knowledge base (KB) em...   \n",
       "2746  We study the problem of knowledge base (KB) em...   \n",
       "2747  We study the problem of knowledge base (KB) em...   \n",
       "\n",
       "                                                 review  \n",
       "2743  This paper proposes a tree-to-tree model aimin...  \n",
       "2744  This paper presents a model to encode and deco...  \n",
       "2745  The paper proposes a unified view of multiple ...  \n",
       "2746  This paper deals with the problem of represent...  \n",
       "2747  The paper proposes a new method to train knowl...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('peer_reviews.csv', usecols = ['abstract', 'review'])\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !wget -O scibert_uncased.tar https://s3-us-west-2.amazonaws.com/ai2-s2-research/scibert/huggingface_pytorch/scibert_scivocab_uncased.tar\n",
    "# !tar -xvf scibert_uncased.tar\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge transformers\n",
    "# conda install -c pytorch pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 'scibert_scivocab_uncased'\n",
    "do_lower_case = True\n",
    "model = BertModel.from_pretrained(model_version)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_version, do_lower_case=do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def embed_text(text, model):\n",
    "    input_ids = torch.tensor(tokenizer.encode(text)).unsqueeze(0)  # Batch size 1\n",
    "    outputs = model(input_ids)\n",
    "    last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple\n",
    "    return last_hidden_states \n",
    "\n",
    "def get_similarity(em, em2):\n",
    "    return cosine_similarity(em.detach().numpy(), em2.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim(ab, re):\n",
    "    try:\n",
    "        abstract = embed_text(ab, model).mean(1)\n",
    "        review = embed_text(re, model).mean(1)\n",
    "        return abstract, review, get_similarity(abstract, review)\n",
    "    except Exception as e:\n",
    "#         print(e)\n",
    "        return 999999999"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data['semantic_similarity'] = data.apply(lambda row: get_sim(row['abstract'], row['review']), axis=1)\n",
    "print(len(data[data['semantic_similarity'] == 999999999]))\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>review</th>\n",
       "      <th>abstract_clean</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>Traditional recurrent neural network (RNN) or ...</td>\n",
       "      <td>This paper proposes a tree-to-tree model aimin...</td>\n",
       "      <td>traditional recurrent neural network  rnn  con...</td>\n",
       "      <td>paper propose tree   tree model aim encode inp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>Traditional recurrent neural network (RNN) or ...</td>\n",
       "      <td>This paper presents a model to encode and deco...</td>\n",
       "      <td>traditional recurrent neural network  rnn  con...</td>\n",
       "      <td>paper present model encode decode tree distrib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>We study the problem of knowledge base (KB) em...</td>\n",
       "      <td>The paper proposes a unified view of multiple ...</td>\n",
       "      <td>study problem knowledge base  kb  embed  usual...</td>\n",
       "      <td>paper propose unify view multiple method learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>We study the problem of knowledge base (KB) em...</td>\n",
       "      <td>This paper deals with the problem of represent...</td>\n",
       "      <td>study problem knowledge base  kb  embed  usual...</td>\n",
       "      <td>paper deal problem representation learn knowle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>We study the problem of knowledge base (KB) em...</td>\n",
       "      <td>The paper proposes a new method to train knowl...</td>\n",
       "      <td>study problem knowledge base  kb  embed  usual...</td>\n",
       "      <td>paper propose new method train knowledge base ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               abstract  \\\n",
       "2743  Traditional recurrent neural network (RNN) or ...   \n",
       "2744  Traditional recurrent neural network (RNN) or ...   \n",
       "2745  We study the problem of knowledge base (KB) em...   \n",
       "2746  We study the problem of knowledge base (KB) em...   \n",
       "2747  We study the problem of knowledge base (KB) em...   \n",
       "\n",
       "                                                 review  \\\n",
       "2743  This paper proposes a tree-to-tree model aimin...   \n",
       "2744  This paper presents a model to encode and deco...   \n",
       "2745  The paper proposes a unified view of multiple ...   \n",
       "2746  This paper deals with the problem of represent...   \n",
       "2747  The paper proposes a new method to train knowl...   \n",
       "\n",
       "                                         abstract_clean  \\\n",
       "2743  traditional recurrent neural network  rnn  con...   \n",
       "2744  traditional recurrent neural network  rnn  con...   \n",
       "2745  study problem knowledge base  kb  embed  usual...   \n",
       "2746  study problem knowledge base  kb  embed  usual...   \n",
       "2747  study problem knowledge base  kb  embed  usual...   \n",
       "\n",
       "                                           review_clean  \n",
       "2743  paper propose tree   tree model aim encode inp...  \n",
       "2744  paper present model encode decode tree distrib...  \n",
       "2745  paper propose unify view multiple method learn...  \n",
       "2746  paper deal problem representation learn knowle...  \n",
       "2747  paper propose new method train knowledge base ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "def data_preprocessing(text):\n",
    "    \n",
    "    nlp = English()\n",
    "    \n",
    "    tokenizer = nlp.Defaults.create_tokenizer(nlp)\n",
    "    text = tokenizer(text)\n",
    "    \n",
    "    spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "    prep = []\n",
    "    \n",
    "    for token in text:\n",
    "        token = token.lemma_\n",
    "        if token.lower() not in spacy_stopwords:\n",
    "            token = re.sub('<[^>]*>', '', token)\n",
    "            token = re.sub('[\\W]+', '', token.lower())\n",
    "            prep.append(token)\n",
    "\n",
    "                \n",
    "    return ' '.join(prep)\n",
    "    \n",
    "        \n",
    "data['abstract_clean'] = data.apply(lambda row: data_preprocessing(row['abstract']), axis=1)\n",
    "data['review_clean'] = data.apply(lambda row: data_preprocessing(row['review']), axis=1)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['abstract_vectors'], data['review_vectors'], data['semantic_similarity_aftercleaning'] = data.apply(lambda row: get_sim(row['abstract_clean'], row['review_clean']), axis=1)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[data['semantic_similarity_aftercleaning'] == 999999999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('scores_vectors.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"\"\"\n",
    " authors propose transform code solution extend work balle 2016  define hyperprior entropy coder model\n",
    " spatial relation transform coefficient   paper good write  trouble follow  result proposal state\n",
    " art  extremely exhaustive comparison method   opinion work good quality present iclr   think excellent improve\n",
    " detail think improve      main issues  main concern motivation relate  1 refer hyperprior motivation  clear\n",
    " gdn propose eliminate statistical dependency pixel image  main motivation gdn coefficient independent\n",
    " confusion resolve broaden explanation figure 2  2 concern clear modify probability distribution entropy\n",
    " encoder improve gdn model  think interest issue  outside scope work  far know  theoretical\n",
    " solution find right balance complexity transformation entropy encoder   interest discuss main novelty work\n",
    " compare method image compression base deep learn      issues  introduction    model optimize end   end\n",
    " minimize total expect code length learn balance information expect improvement entropy model    think point\n",
    " interest  good number happen result present  train procedure  example  simple comparison numb bit signal\n",
    " information depend compression rate numb iteration model train   compression variational models   miss \n",
    " sentence    arithmetic code   transmit     fig1  clear read leave hand scheme  possible include distribution\n",
    " specifically  strange tiledy  scheme different conditional dependency  thing symbol  \n",
    " appear figure use section 2    easy follow change symbol function parameter like theta theta     distortion\n",
    " expect difference    expect  word use      substitute additive uniform noise   phrase correct  author balle\n",
    " 2016 substitute additive uniform noise    equation  1   1 term zero constant  talk equation  7  author\n",
    " 1 term constant       sentence  previous work assume   sound strange    example fig  2 extremely important\n",
    " understand motivation hyperprior think need little explanation  example important need explain begin work\n",
    " real example  model train normalization  specify  gdn able eliminate spatial dependency  dependency eliminate\n",
    " normalization apply spatial coefficient  remove dependency layer different parameter gdn   introduction\n",
    " scale hyperprior   typo   center pane       propose follow extension model  figure 3    colon  maybe miss\n",
    " maybe dot instead colon  lack explanation model   results      probability mass function  need construct\n",
    " fly     computationally costly      batch normalization learn rate decay find beneficial effect  local\n",
    " normalization property gdn  contain global normalization special case     extremely interest  connection batch \n",
    " normalization  decay learn rate   clarify  mean use gdn instead regular nonlinearity long need use batch \n",
    " normalization  word  think batch normalization useful special case gsn  useful community assess benefit \n",
    " local normalization versus global normalization      combination 8 different value  order cover range rate  \n",
    " distortion tradeoff    possible method include lambda input model parameter information    guess include \n",
    " information compute total entropy  numb bit   different way compress image information    metric train evaluate \n",
    " little bite mislead  evaluation plot use different perceptual metric helpful   since ms  ssim yield value\n",
    " 0  wrong  1    compare method achieve value good 09  convert quantity decibel order improve legibility    \n",
    " difference ms  ssim conversion significant  transformation necessary  lose intuition   probably fault able  \n",
    " unconvert  db ms  ssim unit  instance  20 curve surpass value       \n",
    " result differ substantially depend distortion metric use loss function train    informative understand \n",
    " parameter change depend metric employ  little intuition set parameter adapt     figs 5  8 9  curve aggregate \n",
    " different image  mean rate value  note depend totally mislead    nice include result method  like bpg rippel \n",
    " 2017  compare visually   related work  balle et al  publish work include perceptual metric end   \n",
    " end train procedure  think main contribution work  include relate work    end   end optimization \n",
    " nonlinear transform code perceptual quality    laparra  ep simoncelli  pcs  picture coding symposium   \n",
    " 2016   discussion  paragraph discussion section look like 2 section  relate work    think interest author \n",
    " discuss relevance putt effort model hyperprior distribution image  transformation   thing equivalent  \n",
    " reason include hyperprior model ga transformation  clear model distribution output  principle   transformation\n",
    " enforce  use train procedure  transform datum follow impose distribution  gdn powerful output independent  \n",
    " beneficial compression divide problem   references   balle 2016 theis 2017 publish conference year  different \n",
    " year reference confuse    strange reference    j  v laparra  e p simoncelli  2016    density modeling \n",
    " images use generalized  normalization transformation    intl  conf  learning representations  iclr2016   \n",
    " url   httpsarxivorgabs151106281  valero laparra  eero p simoncelli  2015    density modeling images gen  \n",
    " eralized normalization transformation    arxiv e  print  published conference paper  4th international \n",
    " conference learning representations  san juan  2016  arxiv  1511   06281     2016    end   end optimized \n",
    " image compression    arxiv e  print  5th int  conf  learn  ing representations  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = \"\"\"\n",
    "describe end   end trainable model image compression base variational autoencoders  model incorporate \n",
    "hyperprior effectively capture spatial dependency latent representation  hyperprior relate information  concept \n",
    "universal virtually modern image codecs  largely unexplore image compression use artificial neural network  \n",
    "anns   unlike exist autoencoder compression method  model train complex prior jointly underlie autoencoder  \n",
    "demonstrate model lead state    art image compression measure visual quality use popular ms  ssim index  yield \n",
    "rate  distortion performance surpass publish ann  base method evaluate use traditional metric base square error  \n",
    "psnr   furthermore  provide qualitative comparison model train different distortion metric\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similarity(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
